{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd43b810-0d53-40c1-928b-c8cca50fb4c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Theorem 1: FWL\r\n",
    " Let $\\boldsymbol{y} = D\\boldsymbol{\\beta}_1 + W\\boldsymbol{\\beta}_2 + \\boldsymbol{\\mu}$ and let $\\boldsymbol{\\epsilon^Y}$, $\\boldsymbol{\\epsilon^D}$ be $\\boldsymbol{y}$ and $D$ residualized from $W$ respectively. $\\boldsymbol{\\hat{\\beta}}_1$ can be estimated by running OLS of $\\boldsymbol{\\epsilon^Y}$ against $\\boldsymbol{\\epsilon^D}$. \r\n",
    "\r\n",
    "<u>Proof</u>: \r\n",
    "From the original regression, the objective function is the following.\r\n",
    "$$\r\n",
    "\\begin{align*}\r\n",
    "    \\text{min  }\\boldsymbol{e}'\\boldsymbol{e} &= (\\boldsymbol{y} - D\\boldsymbol{\\hat{\\beta}}_1 - W\\boldsymbol{\\hat{\\beta}}_2)'(\\boldsymbol{y} - D\\boldsymbol{\\hat{\\beta}}_1 - W\\boldsymbol{\\hat{\\beta}}_2) \\\\\r\n",
    "    &= \\boldsymbol{y}'\\boldsymbol{y} - 2\\boldsymbol{y}'D\\boldsymbol{\\hat{\\beta}}_1 - 2\\boldsymbol{y}'W\\boldsymbol{\\hat{\\beta}}_2 + 2\\boldsymbol{\\hat{\\beta}}_1'D'W\\boldsymbol{\\hat{\\beta}}_2 + \\boldsymbol{\\hat{\\beta}}_1'D'D\\boldsymbol{\\hat{\\beta}}_1 + \\boldsymbol{\\hat{\\beta}}_2'W'W\\boldsymbol{\\hat{\\beta}}_2\r\n",
    "\\end{align*}\r\n",
    "$$\r\n",
    "The first order conditions are given by the following system\r\n",
    "$$\r\n",
    "\\begin{bmatrix}\r\n",
    "D'D & D'W \\\\\r\n",
    "W'D & W'W \\\\\r\n",
    "\\end{bmatrix}\r\n",
    "\\begin{bmatrix}\r\n",
    "\\boldsymbol{\\hat{\\beta}}_1 \\\\\r\n",
    "\\boldsymbol{\\hat{\\beta}}_2 \\\\\r\n",
    "\\end{bmatrix}\r\n",
    "=\r\n",
    "\\begin{bmatrix}\r\n",
    "D'\\boldsymbol{y} \\\\\r\n",
    "W'\\boldsymbol{y}\r\n",
    "\\end{bmatrix}\r\n",
    "$$\r\n",
    "Lastly, solving for $\\boldsymbol{\\hat{\\beta}}_2$ in the 2nd equation and replacing in the 1st yields the desired result. \r\n",
    "$$\r\n",
    "\\begin{align*}\r\n",
    "    \\boldsymbol{\\hat{\\beta}}_2 &= (W'W)^{-1}[W'\\boldsymbol{y} - W'D\\boldsymbol{\\hat{\\beta}}_1] \\\\\r\n",
    "    &= (W'W)^{-1}W'[\\boldsymbol{y} - D\\boldsymbol{\\hat{\\beta}}_1]\r\n",
    "\\end{align*}\r\n",
    "$$\r\n",
    "In the 1st equation,\r\n",
    "$$D'D\\boldsymbol{\\hat{\\beta}}_1 + D'W\\boldsymbol{\\hat{\\beta}}_2 = D'\\boldsymbol{y}$$\r\n",
    "$$D'D\\boldsymbol{\\hat{\\beta}}_1 + D'W(W'W)^{-1}W'[\\boldsymbol{y} - D\\boldsymbol{\\hat{\\beta}}_1] = D'\\boldsymbol{y}$$\r\n",
    "$$D'D\\boldsymbol{\\hat{\\beta}}_1 + D'P_W[\\boldsymbol{y} - D\\boldsymbol{\\hat{\\beta}}_1] = D'\\boldsymbol{y}$$\r\n",
    "$$D'D\\boldsymbol{\\hat{\\beta}}_1 - D'P_WD\\boldsymbol{\\hat{\\beta}}_1 = D'\\boldsymbol{y} - D'P_W\\boldsymbol{y}$$\r\n",
    "$$D'(I-P_W)D\\boldsymbol{\\hat{\\beta}}_1 = D'(I-P_W)\\boldsymbol{y}$$\r\n",
    "$$D'M_WD\\boldsymbol{\\hat{\\beta}}_1 = D'M_W\\boldsymbol{y}$$\r\n",
    "$$D'M_W'M_WD\\boldsymbol{\\hat{\\beta}}_1 = D'M_W'M_W\\boldsymbol{y}$$\r\n",
    "$$\\boldsymbol{\\hat{\\beta}}_1 = (D'M_W'M_WD)^{-1}D'M_W'M_W\\boldsymbol{y}$$\r\n",
    "$$\\boldsymbol{\\hat{\\beta}}_1 = ({\\epsilon^{D}}^{'}{\\epsilon^{D}})^{-1}\\epsilon^D\\boldsymbol{\\epsilon^Y}$$\r\n",
    "where $P_W$ is $W$'s projection matrix and $M_W$ its residual-maker matrix. \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a35051-b44f-41a9-92a6-6711ae6e90cd",
   "metadata": {},
   "source": [
    "##### Theorem 2: CEF minimizes MSE\n",
    "Let $Y=m(X)+$ where $m(X)=E[Y|X]$ is the CEF and g(X) any other function. The CEF $m(x)$ minimizes E[(Y-g(X))].\n",
    "\n",
    "<u>Proof</u>: \n",
    "$$\n",
    "\\begin{align*}\n",
    "    E[(Y-g(X))^2] &= E[(Y-m(X)+m(X)-g(X))^2] \\\\\n",
    "    &= E[(Y-m(X))^2] + E[(m(X)-g(X))^2] + 2E[Y-m(X)]E[m(X)-g(X)]\n",
    "\\end{align*}\n",
    "$$\n",
    "By the Law of Iterated Expectations, the last term is equal to zero since\n",
    "$$\n",
    "\\begin{align*}\n",
    "    E[Y-m(X)]E[m(X)-g(X)] &= E[E[Y-m(X)]E[m(X)-g(X)] |X] \\\\ \n",
    "    &= E[(E[Y|X] - m(X) )( m(X) - g(X) ) |X] \\\\\n",
    "    &= E[( 0 )( m(X) - g(X) ) |X] = 0\n",
    "\\end{align*}\n",
    "$$\n",
    "So $E[(Y-g(X))^2] = E[(Y-m(X))^2] + E[(m(X)-g(X))^2]$. Since the second term is the expectation of a non-negative variable, \n",
    "$$E[(Y-g(X))^2] \\geq E[(Y-m(X))^2]$$ for any function $g(X)$. This shows that $g(X)=m(X)$ is where the MSE is minimized.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2352fcca-1594-4468-9c97-8e355520e20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"dependency 'lattice' is not available\"also installing the dependencies 'Matrix', 'survival', 'RcppEigen'\n",
      "\n",
      "Warning message:\n",
      "\"unable to access index for repository https://cran.r-project.org/bin/windows/contrib/3.6:\n",
      "  no fue posible abrir la URL 'https://cran.r-project.org/bin/windows/contrib/3.6/PACKAGES'\"Packages which are only available in source form, and may need\n",
      "  compilation of C/C++/Fortran: 'Matrix' 'survival' 'RcppEigen'\n",
      "  'glmnet'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  These will not be installed\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in library(glmnet): there is no package called 'glmnet'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(glmnet): there is no package called 'glmnet'\nTraceback:\n",
      "1. library(glmnet)"
     ]
    }
   ],
   "source": [
    "install.packages(\"glmnet\")\n",
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c4d46f-cf0a-4b22-bbbb-4f9c22cbc2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'C:/Users/ALBERTO TRELLES/Documents/GitHub/CausalAI-Course/labs/replication_1'"
      ],
      "text/latex": [
       "'C:/Users/ALBERTO TRELLES/Documents/GitHub/CausalAI-Course/labs/replication\\_1'"
      ],
      "text/markdown": [
       "'C:/Users/ALBERTO TRELLES/Documents/GitHub/CausalAI-Course/labs/replication_1'"
      ],
      "text/plain": [
       "[1] \"C:/Users/ALBERTO TRELLES/Documents/GitHub/CausalAI-Course/labs/replication_1\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric(0)\n"
     ]
    }
   ],
   "source": [
    "#---(1) Data preparation------#\n",
    "#-----------------------------#\n",
    "#Load data; perform 80/20 split; stablish the index (observations) for the training and test subsets\n",
    "getwd()\n",
    "q3 = get(load(\"../../data/wage2015_subsample_inference.Rdata\"))\n",
    "rm(data)\n",
    "\n",
    "n = dim(q3)[1]\n",
    "nvar = dim(q3)[2]\n",
    "q3$id = seq(1, n, 1) #id variable\n",
    "\n",
    "#--Split----#\n",
    "set.seed(1234)\n",
    "random = sample(1:n, floor(n*8/10), replace = F)  #80/20 split\n",
    "\n",
    "#Training set\n",
    "train = q3[random, ]\n",
    "index_train =  q3[random, ]$id   #Original indexes for Training set\n",
    "ntrain = dim(train)[1]\n",
    "\n",
    "#Testing set\n",
    "test = q3[-random, ]\n",
    "index_test =  q3[-random, ]$id   #Original indexes for Testing set\n",
    "ntest = dim(test)[1]\n",
    "\n",
    "print(intersect(index_train, index_test)) #--> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436e4949-adef-474b-b00d-49867aaa96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---(2) Lambda range------#\n",
    "#-------------------------#\n",
    "lambdas = seq(0.1, 0.5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f07321bd-603a-4dd0-b8a0-e5463c101ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---(3) Partition------#\n",
    "#----------------------#\n",
    "#Divide the training set it 5 folds\n",
    "k=5\n",
    "obsfold = ntrain/k  #824 obs. per fold\n",
    "cutoff = c(obsfold, obsfold*2, obsfold*3, obsfold*4, obsfold*5) \n",
    "\n",
    "#--Folds----#\n",
    "index_f1 = index_train[1:cutoff[1]]\n",
    "index_f2 = index_train[(cutoff[1]+1):cutoff[2]]\n",
    "index_f3 = index_train[(cutoff[2]+1):cutoff[3]]\n",
    "index_f4 = index_train[(cutoff[3]+1):cutoff[4]]\n",
    "index_f5 = index_train[(cutoff[4]+1):cutoff[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb79105-93f5-4f80-8d0c-799c52d72103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>index_f2</th><th scope=col>index_f3</th><th scope=col>index_f4</th><th scope=col>index_f5</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2327</td><td>2654</td><td>1499</td><td> 903</td></tr>\n",
       "\t<tr><td>2761</td><td>3222</td><td>1468</td><td>2940</td></tr>\n",
       "\t<tr><td>1348</td><td>  37</td><td>3142</td><td>1919</td></tr>\n",
       "\t<tr><td> 233</td><td>1274</td><td>2256</td><td>1864</td></tr>\n",
       "\t<tr><td>4027</td><td>4380</td><td>4714</td><td>3585</td></tr>\n",
       "\t<tr><td>3299</td><td>4553</td><td>2423</td><td>3297</td></tr>\n",
       "\t<tr><td> 132</td><td>1846</td><td>3331</td><td>1557</td></tr>\n",
       "\t<tr><td>5061</td><td>3119</td><td>1080</td><td> 531</td></tr>\n",
       "\t<tr><td>3370</td><td>3632</td><td>4603</td><td>4422</td></tr>\n",
       "\t<tr><td>4555</td><td>2554</td><td>2844</td><td>1534</td></tr>\n",
       "\t<tr><td>3651</td><td> 453</td><td>   3</td><td>1688</td></tr>\n",
       "\t<tr><td>1861</td><td> 981</td><td> 433</td><td>2542</td></tr>\n",
       "\t<tr><td>4329</td><td>3160</td><td>3411</td><td>3065</td></tr>\n",
       "\t<tr><td>3749</td><td>3565</td><td>3531</td><td>1164</td></tr>\n",
       "\t<tr><td> 256</td><td>1339</td><td>2036</td><td>1638</td></tr>\n",
       "\t<tr><td>3324</td><td>1707</td><td>2303</td><td>2656</td></tr>\n",
       "\t<tr><td>2131</td><td>3363</td><td>4915</td><td> 410</td></tr>\n",
       "\t<tr><td>1508</td><td>1822</td><td>1808</td><td>4176</td></tr>\n",
       "\t<tr><td>5112</td><td>4860</td><td>1992</td><td>1301</td></tr>\n",
       "\t<tr><td>4212</td><td>4853</td><td>1645</td><td>4222</td></tr>\n",
       "\t<tr><td>3971</td><td>3682</td><td>2320</td><td>1873</td></tr>\n",
       "\t<tr><td>3131</td><td> 700</td><td> 123</td><td>1199</td></tr>\n",
       "\t<tr><td>4976</td><td>1947</td><td>1860</td><td>4851</td></tr>\n",
       "\t<tr><td>4951</td><td>4468</td><td>3341</td><td> 568</td></tr>\n",
       "\t<tr><td> 918</td><td>2886</td><td>4109</td><td>2855</td></tr>\n",
       "\t<tr><td>1139</td><td>1807</td><td>4725</td><td>3499</td></tr>\n",
       "\t<tr><td>4285</td><td>3163</td><td>  64</td><td>2640</td></tr>\n",
       "\t<tr><td>2569</td><td>1726</td><td> 398</td><td>4065</td></tr>\n",
       "\t<tr><td>2081</td><td>2982</td><td>1383</td><td>1721</td></tr>\n",
       "\t<tr><td>4458</td><td>4809</td><td>4414</td><td>2076</td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td> 113</td><td>3072</td><td>1436</td><td>5019</td></tr>\n",
       "\t<tr><td>1666</td><td>2455</td><td>4780</td><td> 666</td></tr>\n",
       "\t<tr><td>3326</td><td>1310</td><td> 267</td><td>1305</td></tr>\n",
       "\t<tr><td>3202</td><td>3605</td><td>3507</td><td>4743</td></tr>\n",
       "\t<tr><td>3902</td><td>4762</td><td>1788</td><td>1795</td></tr>\n",
       "\t<tr><td> 614</td><td>5092</td><td>3797</td><td>3056</td></tr>\n",
       "\t<tr><td>2789</td><td>3211</td><td>4226</td><td>4788</td></tr>\n",
       "\t<tr><td>1769</td><td>2330</td><td>2092</td><td>1589</td></tr>\n",
       "\t<tr><td>2069</td><td>3545</td><td>1149</td><td>2347</td></tr>\n",
       "\t<tr><td> 296</td><td>1484</td><td> 212</td><td>2250</td></tr>\n",
       "\t<tr><td> 794</td><td>3508</td><td> 913</td><td>  44</td></tr>\n",
       "\t<tr><td>3813</td><td>2835</td><td>2018</td><td>2957</td></tr>\n",
       "\t<tr><td>2657</td><td>4035</td><td>3643</td><td>3150</td></tr>\n",
       "\t<tr><td>3648</td><td> 740</td><td> 230</td><td>2653</td></tr>\n",
       "\t<tr><td>2200</td><td>4618</td><td>3709</td><td>1048</td></tr>\n",
       "\t<tr><td>5072</td><td>3514</td><td>4187</td><td>2245</td></tr>\n",
       "\t<tr><td> 660</td><td>4490</td><td>1123</td><td> 411</td></tr>\n",
       "\t<tr><td>3255</td><td>3025</td><td>4345</td><td>3652</td></tr>\n",
       "\t<tr><td>3503</td><td>2233</td><td>2424</td><td>2965</td></tr>\n",
       "\t<tr><td>3024</td><td> 714</td><td> 503</td><td>2737</td></tr>\n",
       "\t<tr><td>3358</td><td>1579</td><td>2926</td><td>  77</td></tr>\n",
       "\t<tr><td>2760</td><td> 264</td><td>4742</td><td>2486</td></tr>\n",
       "\t<tr><td>3570</td><td>2800</td><td>3421</td><td> 504</td></tr>\n",
       "\t<tr><td> 651</td><td>2216</td><td>4802</td><td>4639</td></tr>\n",
       "\t<tr><td>  27</td><td> 687</td><td>1562</td><td>3616</td></tr>\n",
       "\t<tr><td>1536</td><td>3543</td><td>1312</td><td>2670</td></tr>\n",
       "\t<tr><td>1731</td><td>2370</td><td>3348</td><td>5011</td></tr>\n",
       "\t<tr><td>4314</td><td>5067</td><td>4105</td><td>3517</td></tr>\n",
       "\t<tr><td>1218</td><td>3307</td><td>2978</td><td> 796</td></tr>\n",
       "\t<tr><td>1780</td><td>2282</td><td>3549</td><td>2059</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llll}\n",
       " index\\_f2 & index\\_f3 & index\\_f4 & index\\_f5\\\\\n",
       "\\hline\n",
       "\t 2327 & 2654 & 1499 &  903\\\\\n",
       "\t 2761 & 3222 & 1468 & 2940\\\\\n",
       "\t 1348 &   37 & 3142 & 1919\\\\\n",
       "\t  233 & 1274 & 2256 & 1864\\\\\n",
       "\t 4027 & 4380 & 4714 & 3585\\\\\n",
       "\t 3299 & 4553 & 2423 & 3297\\\\\n",
       "\t  132 & 1846 & 3331 & 1557\\\\\n",
       "\t 5061 & 3119 & 1080 &  531\\\\\n",
       "\t 3370 & 3632 & 4603 & 4422\\\\\n",
       "\t 4555 & 2554 & 2844 & 1534\\\\\n",
       "\t 3651 &  453 &    3 & 1688\\\\\n",
       "\t 1861 &  981 &  433 & 2542\\\\\n",
       "\t 4329 & 3160 & 3411 & 3065\\\\\n",
       "\t 3749 & 3565 & 3531 & 1164\\\\\n",
       "\t  256 & 1339 & 2036 & 1638\\\\\n",
       "\t 3324 & 1707 & 2303 & 2656\\\\\n",
       "\t 2131 & 3363 & 4915 &  410\\\\\n",
       "\t 1508 & 1822 & 1808 & 4176\\\\\n",
       "\t 5112 & 4860 & 1992 & 1301\\\\\n",
       "\t 4212 & 4853 & 1645 & 4222\\\\\n",
       "\t 3971 & 3682 & 2320 & 1873\\\\\n",
       "\t 3131 &  700 &  123 & 1199\\\\\n",
       "\t 4976 & 1947 & 1860 & 4851\\\\\n",
       "\t 4951 & 4468 & 3341 &  568\\\\\n",
       "\t  918 & 2886 & 4109 & 2855\\\\\n",
       "\t 1139 & 1807 & 4725 & 3499\\\\\n",
       "\t 4285 & 3163 &   64 & 2640\\\\\n",
       "\t 2569 & 1726 &  398 & 4065\\\\\n",
       "\t 2081 & 2982 & 1383 & 1721\\\\\n",
       "\t 4458 & 4809 & 4414 & 2076\\\\\n",
       "\t ... & ... & ... & ...\\\\\n",
       "\t  113 & 3072 & 1436 & 5019\\\\\n",
       "\t 1666 & 2455 & 4780 &  666\\\\\n",
       "\t 3326 & 1310 &  267 & 1305\\\\\n",
       "\t 3202 & 3605 & 3507 & 4743\\\\\n",
       "\t 3902 & 4762 & 1788 & 1795\\\\\n",
       "\t  614 & 5092 & 3797 & 3056\\\\\n",
       "\t 2789 & 3211 & 4226 & 4788\\\\\n",
       "\t 1769 & 2330 & 2092 & 1589\\\\\n",
       "\t 2069 & 3545 & 1149 & 2347\\\\\n",
       "\t  296 & 1484 &  212 & 2250\\\\\n",
       "\t  794 & 3508 &  913 &   44\\\\\n",
       "\t 3813 & 2835 & 2018 & 2957\\\\\n",
       "\t 2657 & 4035 & 3643 & 3150\\\\\n",
       "\t 3648 &  740 &  230 & 2653\\\\\n",
       "\t 2200 & 4618 & 3709 & 1048\\\\\n",
       "\t 5072 & 3514 & 4187 & 2245\\\\\n",
       "\t  660 & 4490 & 1123 &  411\\\\\n",
       "\t 3255 & 3025 & 4345 & 3652\\\\\n",
       "\t 3503 & 2233 & 2424 & 2965\\\\\n",
       "\t 3024 &  714 &  503 & 2737\\\\\n",
       "\t 3358 & 1579 & 2926 &   77\\\\\n",
       "\t 2760 &  264 & 4742 & 2486\\\\\n",
       "\t 3570 & 2800 & 3421 &  504\\\\\n",
       "\t  651 & 2216 & 4802 & 4639\\\\\n",
       "\t   27 &  687 & 1562 & 3616\\\\\n",
       "\t 1536 & 3543 & 1312 & 2670\\\\\n",
       "\t 1731 & 2370 & 3348 & 5011\\\\\n",
       "\t 4314 & 5067 & 4105 & 3517\\\\\n",
       "\t 1218 & 3307 & 2978 &  796\\\\\n",
       "\t 1780 & 2282 & 3549 & 2059\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| index_f2 | index_f3 | index_f4 | index_f5 |\n",
       "|---|---|---|---|\n",
       "| 2327 | 2654 | 1499 |  903 |\n",
       "| 2761 | 3222 | 1468 | 2940 |\n",
       "| 1348 |   37 | 3142 | 1919 |\n",
       "|  233 | 1274 | 2256 | 1864 |\n",
       "| 4027 | 4380 | 4714 | 3585 |\n",
       "| 3299 | 4553 | 2423 | 3297 |\n",
       "|  132 | 1846 | 3331 | 1557 |\n",
       "| 5061 | 3119 | 1080 |  531 |\n",
       "| 3370 | 3632 | 4603 | 4422 |\n",
       "| 4555 | 2554 | 2844 | 1534 |\n",
       "| 3651 |  453 |    3 | 1688 |\n",
       "| 1861 |  981 |  433 | 2542 |\n",
       "| 4329 | 3160 | 3411 | 3065 |\n",
       "| 3749 | 3565 | 3531 | 1164 |\n",
       "|  256 | 1339 | 2036 | 1638 |\n",
       "| 3324 | 1707 | 2303 | 2656 |\n",
       "| 2131 | 3363 | 4915 |  410 |\n",
       "| 1508 | 1822 | 1808 | 4176 |\n",
       "| 5112 | 4860 | 1992 | 1301 |\n",
       "| 4212 | 4853 | 1645 | 4222 |\n",
       "| 3971 | 3682 | 2320 | 1873 |\n",
       "| 3131 |  700 |  123 | 1199 |\n",
       "| 4976 | 1947 | 1860 | 4851 |\n",
       "| 4951 | 4468 | 3341 |  568 |\n",
       "|  918 | 2886 | 4109 | 2855 |\n",
       "| 1139 | 1807 | 4725 | 3499 |\n",
       "| 4285 | 3163 |   64 | 2640 |\n",
       "| 2569 | 1726 |  398 | 4065 |\n",
       "| 2081 | 2982 | 1383 | 1721 |\n",
       "| 4458 | 4809 | 4414 | 2076 |\n",
       "| ... | ... | ... | ... |\n",
       "|  113 | 3072 | 1436 | 5019 |\n",
       "| 1666 | 2455 | 4780 |  666 |\n",
       "| 3326 | 1310 |  267 | 1305 |\n",
       "| 3202 | 3605 | 3507 | 4743 |\n",
       "| 3902 | 4762 | 1788 | 1795 |\n",
       "|  614 | 5092 | 3797 | 3056 |\n",
       "| 2789 | 3211 | 4226 | 4788 |\n",
       "| 1769 | 2330 | 2092 | 1589 |\n",
       "| 2069 | 3545 | 1149 | 2347 |\n",
       "|  296 | 1484 |  212 | 2250 |\n",
       "|  794 | 3508 |  913 |   44 |\n",
       "| 3813 | 2835 | 2018 | 2957 |\n",
       "| 2657 | 4035 | 3643 | 3150 |\n",
       "| 3648 |  740 |  230 | 2653 |\n",
       "| 2200 | 4618 | 3709 | 1048 |\n",
       "| 5072 | 3514 | 4187 | 2245 |\n",
       "|  660 | 4490 | 1123 |  411 |\n",
       "| 3255 | 3025 | 4345 | 3652 |\n",
       "| 3503 | 2233 | 2424 | 2965 |\n",
       "| 3024 |  714 |  503 | 2737 |\n",
       "| 3358 | 1579 | 2926 |   77 |\n",
       "| 2760 |  264 | 4742 | 2486 |\n",
       "| 3570 | 2800 | 3421 |  504 |\n",
       "|  651 | 2216 | 4802 | 4639 |\n",
       "|   27 |  687 | 1562 | 3616 |\n",
       "| 1536 | 3543 | 1312 | 2670 |\n",
       "| 1731 | 2370 | 3348 | 5011 |\n",
       "| 4314 | 5067 | 4105 | 3517 |\n",
       "| 1218 | 3307 | 2978 |  796 |\n",
       "| 1780 | 2282 | 3549 | 2059 |\n",
       "\n"
      ],
      "text/plain": [
       "      index_f2 index_f3 index_f4 index_f5\n",
       " [1,] 2327     2654     1499      903    \n",
       " [2,] 2761     3222     1468     2940    \n",
       " [3,] 1348       37     3142     1919    \n",
       " [4,]  233     1274     2256     1864    \n",
       " [5,] 4027     4380     4714     3585    \n",
       " [6,] 3299     4553     2423     3297    \n",
       " [7,]  132     1846     3331     1557    \n",
       " [8,] 5061     3119     1080      531    \n",
       " [9,] 3370     3632     4603     4422    \n",
       "[10,] 4555     2554     2844     1534    \n",
       "[11,] 3651      453        3     1688    \n",
       "[12,] 1861      981      433     2542    \n",
       "[13,] 4329     3160     3411     3065    \n",
       "[14,] 3749     3565     3531     1164    \n",
       "[15,]  256     1339     2036     1638    \n",
       "[16,] 3324     1707     2303     2656    \n",
       "[17,] 2131     3363     4915      410    \n",
       "[18,] 1508     1822     1808     4176    \n",
       "[19,] 5112     4860     1992     1301    \n",
       "[20,] 4212     4853     1645     4222    \n",
       "[21,] 3971     3682     2320     1873    \n",
       "[22,] 3131      700      123     1199    \n",
       "[23,] 4976     1947     1860     4851    \n",
       "[24,] 4951     4468     3341      568    \n",
       "[25,]  918     2886     4109     2855    \n",
       "[26,] 1139     1807     4725     3499    \n",
       "[27,] 4285     3163       64     2640    \n",
       "[28,] 2569     1726      398     4065    \n",
       "[29,] 2081     2982     1383     1721    \n",
       "[30,] 4458     4809     4414     2076    \n",
       "[31,] ...      ...      ...      ...     \n",
       "[32,]  113     3072     1436     5019    \n",
       "[33,] 1666     2455     4780      666    \n",
       "[34,] 3326     1310      267     1305    \n",
       "[35,] 3202     3605     3507     4743    \n",
       "[36,] 3902     4762     1788     1795    \n",
       "[37,]  614     5092     3797     3056    \n",
       "[38,] 2789     3211     4226     4788    \n",
       "[39,] 1769     2330     2092     1589    \n",
       "[40,] 2069     3545     1149     2347    \n",
       "[41,]  296     1484      212     2250    \n",
       "[42,]  794     3508      913       44    \n",
       "[43,] 3813     2835     2018     2957    \n",
       "[44,] 2657     4035     3643     3150    \n",
       "[45,] 3648      740      230     2653    \n",
       "[46,] 2200     4618     3709     1048    \n",
       "[47,] 5072     3514     4187     2245    \n",
       "[48,]  660     4490     1123      411    \n",
       "[49,] 3255     3025     4345     3652    \n",
       "[50,] 3503     2233     2424     2965    \n",
       "[51,] 3024      714      503     2737    \n",
       "[52,] 3358     1579     2926       77    \n",
       "[53,] 2760      264     4742     2486    \n",
       "[54,] 3570     2800     3421      504    \n",
       "[55,]  651     2216     4802     4639    \n",
       "[56,]   27      687     1562     3616    \n",
       "[57,] 1536     3543     1312     2670    \n",
       "[58,] 1731     2370     3348     5011    \n",
       "[59,] 4314     5067     4105     3517    \n",
       "[60,] 1218     3307     2978      796    \n",
       "[61,] 1780     2282     3549     2059    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in glmnet(x, y, alpha = 1, lambda = lambdas[p]): no se pudo encontrar la función \"glmnet\"\n",
     "output_type": "error",
     "traceback": [
      "Error in glmnet(x, y, alpha = 1, lambda = lambdas[p]): no se pudo encontrar la función \"glmnet\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "#---(4) Lasso function------#    #glmnet()\n",
    "#---------------------------#\n",
    "#we'll use glmnet()\n",
    "\n",
    "#---(5) CV loop------#\n",
    "#--------------------#\n",
    "folds = cbind(index_f1, index_f2, index_f3, index_f4, index_f5)  #matrix of fold's indexes; each column is are the indexes of a single fold\n",
    "folds[,-1]\n",
    "\n",
    "MSE_mat = matrix(data=NA, nrow=5, ncol=length(lambdas))     #each row is a fold; each col is a lambda numer\n",
    "\n",
    "\n",
    "for (p in 1:length(lambdas)){\n",
    "  \n",
    "for (i in 1:k) {\n",
    "  index_training = folds[, -i]   #train with each observation of each fold except for current i \n",
    "  index_validation = folds[, i]  #validate the model with current i and get MSE\n",
    "  \n",
    "  x = q3[index_training, !names(q3) %in% c(\"wage\", \"lwage\", \"id\")]\n",
    "  y = q3$wage[index_training]\n",
    "  \n",
    "  model = glmnet(x, y, alpha=1, lambda=lambdas[p])\n",
    "  coefficients = coef(model)\n",
    "  \n",
    "  \n",
    "  #Validation\n",
    "  x_validation = q3[index_validation, !names(q3) %in% c(\"wage\", \"lwage\", \"id\")]\n",
    "  y_validation = q3$wage[index_validation]\n",
    "  \n",
    "  pred = predict(model, newx=as.matrix(x_validation))   #Take unused fold and predict y_hat\n",
    "  mse = mean((y_validation - pred)^2)                   #Compare with y, take MSE\n",
    "  MSE_mat[p,i] = mse\n",
    "  \n",
    "}\n",
    "  \n",
    "}\n",
    "colnames(MSE_mat) = c(\"lambda1\", \"lambda2\", \"lambda3\", \"lambda4\", \"lambda5\")\n",
    "print(MSE_mat) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c1280b6-6cb6-45d8-9d01-b6440b0063cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal lambda from our list 0.1 0.2 0.3 0.4 0.5 is  "
     ]
    }
   ],
   "source": [
    "#---(6) Optimal lambda------#\n",
    "#---------------------------#\n",
    "means_mse = apply(MSE_mat, 2, mean)\n",
    "optimal_pos = which.min(means_mse)\n",
    "\n",
    "#OPTIMAL LAMBDA\n",
    "optimal_lambda = lambdas[optimal_pos]\n",
    "cat(\"The average MSE of each lambda value was: \", means_mse)\n",
    "cat(\"The optimal lambda from our list\", lambdas, \"is \", optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1eb15f-21cf-465a-a2b3-aa630c9f531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---(7) Model Training------#\n",
    "#---------------------------#\n",
    "#Using the optimal_lambda to train a model in the initial training set (80%)\n",
    "x = q3[index_train, !names(q3) %in% c(\"wage\", \"lwage\", \"id\")]\n",
    "y = q3$wage[index_train]\n",
    "\n",
    "model = glmnet(x, y, alpha=1, lambda=optimal_lambda)\n",
    "\n",
    "#Validating the model using the test set (20%)\n",
    "x_test = q3[index_test, !names(q3) %in% c(\"wage\", \"lwage\", \"id\")]\n",
    "y_test = q3$wage[index_test]\n",
    "\n",
    "pred = predict(model, newx=as.matrix(x_test))\n",
    "MSE = mean((y_test - pred)^2)\n",
    "cat(\"The MSE of the final model evaluated in the test sample (20% split) is: \", MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03821099-a0f5-401d-9733-c7cfc9de3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---(8) Results------#\n",
    "#--------------------#\n",
    "#From the initial list c(0.1, 0.2, 0.3, 0.4, 0.5), the optimal lambda value was 0.5\n",
    "#Given that the average MSE for each lambda value was 5167.2899,  8620.5168, 25934.3097,  1377.3341,   824.8698, \n",
    "#respectively, this suggest we could get a lower average MSE by using a higher lambda\n",
    "\n",
    "#After performing cross-validation, its performance on the test set which accounts for 20% of the original data yields a MSE of 454.8124"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
